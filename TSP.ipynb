{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstration TSP - Branch and Cut\n",
    "The Traveling Salesman Problem (TSP), also known as a Hamilton path, regards to finding a path that visits each node in a graph exactly once. If we have a complete graph we know that such a path exists, but finding the shortest Hamilton path, in a complete graph, is an optmization problem. It is NP-complete, and thus, there does not exist an algorithm that can guarantee to find a solution within a ´reasonable´ amount of time. The reason beeing that only an exhaustive search through all possible combinations can guarantee that a solution is valid and optimal. This means that the number of possible solutions grows exponentially in relation to the input size of the problem. The goal is often to keep the problem size small and to push the exponential growth.\n",
    "\n",
    "To solve optimization problems of this character there exists a variety of techniques that can be used. What teqchniques to chose depends on the problem. If the problem size is small enough an optimal solution can be found. For larger problems the common approach is to find a solution that is 'good enough', this is usally measured with bounds. \n",
    "\n",
    "Back to TSP. We will generate a graph where we already know the shortest distance. This is done in the code below. It displays the generated graph along with the distance of the shortest path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_graph import generate_star_shaped_graph, plot_ordered_graph\n",
    "\n",
    "vertices = generate_star_shaped_graph(num_nodes=12)\n",
    "plot_ordered_graph(vertices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The problem\n",
    "Let us assume that our list of vertices describes a complete graph. And our task is to find the shortest distance that visits each vertice exactly once. First, we randomize our current list. Then we plot the new path along with the complete graph to illustrate the complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from utils_graph import plot_complete_graph\n",
    "\n",
    "random.shuffle(vertices)\n",
    "plot_ordered_graph(vertices)\n",
    "plot_complete_graph(vertices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distance of the randomized order is, unsurprisingly, a lot larger than the optimal distance. The complete graph also shows how the number of edges grows exponentially in relation to the number of vertices. Testing all possible paths is called an exhaustive search, and the time complexity is exponential (NP-hard)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Model\n",
    "\n",
    "To address the problem of finding the shortest Hamiltonian path in a complete graph, we begin by defining our problem. Consider a graph $G$ consisting of $n$ vertices and $m$ edges.\n",
    "\n",
    "### Graph Representation\n",
    "\n",
    "The graph $G$ is complete, meaning that there is an edge between every pair of distinct vertices. This can be represented by an $ n \\times n$ adjacency matrix $ A$, where $A[i][j]$ is 1 if there is an edge between vertex $i$ and vertex $j$, and 0 otherwise. Since the graph is complete,$ A[i][j] = 1$ for all $ i \\neq j$.\n",
    "\n",
    "### Hamiltonian Path\n",
    "\n",
    "A Hamiltonian path is a path in the graph that visits each vertex exactly once and returns to the starting vertex, forming a cycle. In our case, we are interested in finding the shortest Hamiltonian path, i.e., the path with the minimum total edge weight - represented as distance.\n",
    "\n",
    "### Objective Function\n",
    "\n",
    "The objective is to minimize the total weight of the Hamiltonian path. This can be expressed as an objective function $f(P)$, where $P$ is a permutation of the vertices representing a potential Hamiltonian path. The objective is to find the permutation $P$ that minimizes $f(P)$.\n",
    "\n",
    "### Decision Variables\n",
    "\n",
    "The decision variables are the edges in the Hamiltonian path. We can use binary variables $x_{ij}$ to indicate whether the edge between vertices $i$ and $j$ is included in the path. The decision variable matrix $X$ is an $n \\times n$ matrix, where $X[i][j] = 1$ if $x_{ij}$ is included in the path and 0 otherwise.\n",
    "\n",
    "### Constraints\n",
    "\n",
    "1. **Vertex Visit Constraints:** Each vertex must be visited exactly once in the Hamiltonian path. \n",
    "   $$\n",
    "   \\sum_{i=1}^{n} x_{ij} = 1 \\quad \\text{for } j = 1, 2, \\ldots, n\n",
    "   $$\n",
    "   $$\n",
    "   \\sum_{j=1}^{n} x_{ij} = 1 \\quad \\text{for } i = 1, 2, \\ldots, n\n",
    "   $$\n",
    "   $$\n",
    "   x_{ij} = \\{0,1\\}\n",
    "   $$\n",
    "\n",
    "### Objective Function and Constraints\n",
    "\n",
    "Combining the objective function and constraints, we can formulate the mathematical model for finding the shortest Hamiltonian path in a complete graph.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Programming & Linear Relaxation\n",
    "Our model fits perfect for Linear Programming. As a matter of fact, Mixed Integer Programming (MIP) is an effecient method for solving TSP. In this case, I will use LP to achive an upper bound. We will break our constraint that $x_{i,j} = {0,1}, instead get a real number $x_{i,j} = [0,1]$. Since LP is not restricted to Integers, it will return a value(distance) that is either the optimal value or less: $LP(P) \\leq f(P)$. \n",
    "\n",
    "Let us use Google ortools to get the linear relaxation (ortools implementation can be found in utils_optimization.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_optimization import linnear_relaxation_tsp\n",
    "\n",
    "_,solver,X = linnear_relaxation_tsp(vertices)\n",
    "print(\"Objective value =\", solver.Objective().Value())\n",
    "values = []\n",
    "for i in range(len(vertices)):\n",
    "    for j in range(len(vertices)):\n",
    "        if X[i,j].solution_value() > 0:\n",
    "            print(X[i,j].name(), \" = \", X[i,j].solution_value())\n",
    "            values.append(((i,j), X[i,j].solution_value()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got an objective value far less than the optimal value. This is expected since the we violate the constraint $x_{i,j} = {0,1}$. But the strength of this LP-algorithm is that it is fast. We can now use it for branching. Let us find a decisionvarable, $x_{i,j}$, with a value close to 0.5 - and branch on that variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "differences = [(name, abs(val - 0.5)) for name,val in values]\n",
    "x_to_branch, target_value = differences[0]\n",
    "for x_next, value in differences[1:]:\n",
    "    if value < target_value:\n",
    "        x_to_branch = x_next\n",
    "print(\"X to branch on is \", x_next)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_optimization import add_lp_constraint, lp_tsp_branch, solve_lp\n",
    "# Branch by setting x-value to 1\n",
    "add_lp_constraint(solver, X, x_to_branch, 1)\n",
    "_,solver = solve_lp(solver)\n",
    "print(f\"Objective value with X[{x_to_branch}] = 1\", solver.Objective().Value())\n",
    "\n",
    "# Branch by setting x-value to 0\n",
    "# Build new model, ortools do not support solver to remove constraints\n",
    "_,solver_new,X_new = lp_tsp_branch(vertices,[(x_to_branch,0)])\n",
    "print(f\"Objective value with X[{x_to_branch}] = 0\", solver_new.Objective().Value())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare the branch-values\n",
    "Using the result from LP we now know what value to set $x_{ij}$, namely the value that gives the least value. We can now continue to pick the next undecided decision-variable to branch on. \n",
    "\n",
    "> Note: I use ortools in this notebook to showcase the theory on how to use LP to help with branch and bound (branch and cut), but the implementation is far from offiecent with the Python wrapper. There are exellent MIP-solvers that one can use instead.\n",
    "\n",
    "Let us make a loop that continously use LP to get a feasable solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_optimization import get_x_to_branch, add_lp_constraint, lp_tsp_branch, solve_lp\n",
    "branch_choices = []\n",
    "num_vertices = len(vertices)\n",
    "included_vertices = 0\n",
    "status,solver,X = lp_tsp_branch(vertices,branch_choices)\n",
    "\n",
    "while included_vertices < num_vertices:\n",
    "    print(\"decisions made: \")\n",
    "    print(branch_choices)\n",
    "    x_to_branch, _ = get_x_to_branch(X,num_vertices)\n",
    "    if x_to_branch == 1:\n",
    "        break\n",
    "    # Check branch on x_ij = 1\n",
    "    branch_include = (x_to_branch, 1)\n",
    "    add_lp_constraint(solver, X, x_to_branch, 1)\n",
    "    status_include, solver = solve_lp(solver)\n",
    "\n",
    "    if status_include == 0:\n",
    "        print(f\"Objective value with X[{x_to_branch}] = 1\", solver.Objective().Value())\n",
    "    \n",
    "    # Check branch on x_ij = 0\n",
    "    branch_exclude = (x_to_branch, 0)\n",
    "    branch_choices.append(branch_exclude)\n",
    "    status_exclude,solver_new,X_new = lp_tsp_branch(vertices,branch_choices)\n",
    "\n",
    "    if status_exclude == 0:\n",
    "        print(f\"Objective value with X[{x_to_branch}] = 0\", solver_new.Objective().Value())\n",
    "    \n",
    "    if status_exclude == 0 and status_include == 0:\n",
    "        # Compare the result and cut \n",
    "        if solver_new.Objective().Value() < solver.Objective().Value():\n",
    "            solver = solver_new\n",
    "            X = X_new\n",
    "        else:\n",
    "            branch_choices.pop()\n",
    "            branch_choices.append(branch_include)\n",
    "            included_vertices += 1\n",
    "    elif status_exclude == 0:\n",
    "        solver = solver_new\n",
    "        X = X_new\n",
    "    elif status_include == 0:\n",
    "        branch_choices.pop()\n",
    "        branch_choices.append(branch_include)\n",
    "        included_vertices += 1\n",
    "    else:\n",
    "        print(\"Both failed.\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get edges\n",
    "\n",
    "solution_edges = [0]\n",
    "    \n",
    "while len(solution_edges) < num_vertices:\n",
    "    u = solution_edges[-1]\n",
    "    for v in range(num_vertices):\n",
    "        if X[u,v].solution_value() > 0:\n",
    "            solution_edges.append(v)\n",
    "            break\n",
    "            \n",
    "print(solution_edges)\n",
    "print(vertices)\n",
    "solution = []\n",
    "for i in solution_edges:\n",
    "    solution.append(vertices[i])\n",
    "    \n",
    "print(solution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check new solution\n",
    "Our new solution is not the optimal. Let us plot it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot solution\n",
    "plot_ordered_graph(solution)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is however much greater than the randomized one. We now have an upper bound from LP and a lower bound from our latest solution. We know that the optimal solution is somewhere between. This can be done using exhaustive search."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
